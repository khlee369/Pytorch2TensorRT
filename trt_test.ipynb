{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_path = 'sample.trt'\n",
    "image_path = ''\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine(engine_path):\n",
    "    # If a serialized engine exists, use it instead of building an engine.\n",
    "    print(\"Reading engine from file {}\".format(engine_path))\n",
    "    with open(engine_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "        return runtime.deserialize_cuda_engine(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_buffers(engine, batch_size):\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    bindings = []\n",
    "    stream = cuda.Stream()\n",
    "    for binding in engine:\n",
    "\n",
    "        size = trt.volume(engine.get_binding_shape(binding)) * batch_size\n",
    "        dims = engine.get_binding_shape(binding)\n",
    "        \n",
    "        # in case batch dimension is -1 (dynamic)\n",
    "        if dims[0] < 0:\n",
    "            size *= -1\n",
    "        \n",
    "        dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "        # Allocate host and device buffers\n",
    "        host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "        device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "        # Append the device buffer to device bindings.\n",
    "        bindings.append(int(device_mem))\n",
    "        # Append to the appropriate list.\n",
    "        if engine.binding_is_input(binding):\n",
    "            inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "        else:\n",
    "            outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    return inputs, outputs, bindings, stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_inference(context, bindings, inputs, outputs, stream):\n",
    "    # Transfer input data to the GPU.\n",
    "    [cuda.memcpy_htod_async(inp.device, inp.host, stream) for inp in inputs]\n",
    "    # Run inference.\n",
    "    context.execute_async(bindings=bindings, stream_handle=stream.handle)\n",
    "    # Transfer predictions back from the GPU.\n",
    "    [cuda.memcpy_dtoh_async(out.host, out.device, stream) for out in outputs]\n",
    "    # Synchronize the stream\n",
    "    stream.synchronize()\n",
    "    # Return only the host outputs.\n",
    "    return [out.host for out in outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(context, buffers, image_src, image_size, num_classes):\n",
    "    IN_IMAGE_H, IN_IMAGE_W = image_size\n",
    "\n",
    "    ta = time.time()\n",
    "    # Input\n",
    "    # resized = cv2.resize(image_src, (IN_IMAGE_W, IN_IMAGE_H), interpolation=cv2.INTER_LINEAR)\n",
    "    # img_in = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "    # img_in = np.transpose(img_in, (2, 0, 1)).astype(np.float32)\n",
    "    # img_in = np.expand_dims(img_in, axis=0)\n",
    "    # img_in /= 255.0\n",
    "    img_in = image_src.astype(np.float32)\n",
    "    img_in = np.ascontiguousarray(img_in)\n",
    "    print(\"Shape of the network input: \", img_in.shape)\n",
    "    # print(img_in)\n",
    "\n",
    "    inputs, outputs, bindings, stream = buffers\n",
    "    print('Length of inputs: ', len(inputs))\n",
    "    inputs[0].host = img_in\n",
    "\n",
    "    trt_outputs = do_inference(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "\n",
    "    print('Len of outputs: ', len(trt_outputs))\n",
    "\n",
    "    # trt_outputs[0] = trt_outputs[0].reshape(1, -1, 1, 4)\n",
    "    # trt_outputs[1] = trt_outputs[1].reshape(1, -1, num_classes)\n",
    "\n",
    "    tb = time.time()\n",
    "\n",
    "    print('-----------------------------------')\n",
    "    print('    TRT inference time: %f' % (tb - ta))\n",
    "    print('-----------------------------------')\n",
    "\n",
    "    # boxes = post_processing(img_in, 0.4, 0.6, trt_outputs)\n",
    "    trt_outputs = trt_outputs[0].reshape((1, 672, 672))\n",
    "    boxes = trt_outputs\n",
    "\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger()\n",
    "cuda.init()\n",
    "device = cuda.Device(0)  # enter your Gpu id here\n",
    "ctx = device.make_context()\n",
    "\n",
    "# allocate_buffers()  # load Cuda buffers or any other Cuda or TenosrRT operations\n",
    "\n",
    "# ctx.pop()  # very important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading engine from file sample.trt\n",
      "Shape of the network input:  (1, 1, 224, 224)\n",
      "Length of inputs:  1\n",
      "Len of outputs:  1\n",
      "-----------------------------------\n",
      "    TRT inference time: 0.001116\n",
      "-----------------------------------\n",
      "Shape of the network input:  (1, 1, 224, 224)\n",
      "Length of inputs:  1\n",
      "Len of outputs:  1\n",
      "-----------------------------------\n",
      "    TRT inference time: 0.001394\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "with get_engine(engine_path) as engine, engine.create_execution_context() as context:\n",
    "    buffers = allocate_buffers(engine, 1)\n",
    "    IN_IMAGE_H, IN_IMAGE_W = image_size\n",
    "    context.set_binding_shape(0, (1, 1, IN_IMAGE_H, IN_IMAGE_W))\n",
    "\n",
    "    # image_src = cv2.imread(image_path)\n",
    "    image_src = np.ones([1, 1, 224, 224])\n",
    "\n",
    "    num_classes = 80\n",
    "\n",
    "    for i in range(2):  # This 'for' loop is for speed check\n",
    "                            # Because the first iteration is usually longer\n",
    "        boxes = detect(context, buffers, image_src, image_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.76464844, 0.87353516, 0.9038086 , ..., 0.85595703,\n",
       "         0.7841797 , 0.7133789 ],\n",
       "        [0.82421875, 1.0136719 , 1.1044922 , ..., 1.1005859 ,\n",
       "         1.0097656 , 0.79589844],\n",
       "        [0.8491211 , 1.0742188 , 1.140625  , ..., 1.1074219 ,\n",
       "         1.0810547 , 0.8432617 ],\n",
       "        ...,\n",
       "        [0.92529297, 1.0283203 , 1.0556641 , ..., 1.0234375 ,\n",
       "         1.0800781 , 0.9033203 ],\n",
       "        [0.8520508 , 0.9140625 , 0.9482422 , ..., 0.9824219 ,\n",
       "         1.0068359 , 0.86816406],\n",
       "        [0.75683594, 0.7729492 , 0.77734375, ..., 0.75390625,\n",
       "         0.8017578 , 0.77246094]]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
